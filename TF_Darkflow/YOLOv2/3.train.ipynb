{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 15256\r\n",
      "-rw-rw-r-- 1 cesare cesare     2174  三  30 10:22 1.processing_video_darkflow.py\r\n",
      "-rw-rw-r-- 1 cesare cesare      555  三  30 15:21 1.processing_video_darkflow_saved.ipynb\r\n",
      "-rw-rw-r-- 1 cesare cesare     2259  三  30 10:46 1.processing_video_darkflow_saved.py\r\n",
      "drwxr-xr-x 2 cesare cesare     4096  三  26 14:40 \u001b[0m\u001b[01;34mbin\u001b[0m/\r\n",
      "drwxrwxr-x 4 cesare cesare     4096  三  26 12:46 \u001b[01;34mbuild\u001b[0m/\r\n",
      "drwxrwxr-x 4 cesare cesare     4096  三  27 18:55 \u001b[01;34mcfg\u001b[0m/\r\n",
      "drwxrwxr-x 2 cesare cesare     4096  三  28 09:53 \u001b[01;34mckpt\u001b[0m/\r\n",
      "drwxrwxr-x 7 cesare cesare     4096  三  26 12:46 \u001b[01;34mdarkflow\u001b[0m/\r\n",
      "-rw-rw-r-- 1 cesare cesare 14900940  三  25 10:17 \u001b[01;35mdemo.gif\u001b[0m\r\n",
      "-rw-rw-r-- 1 cesare cesare   163759  三  26 12:26 \u001b[01;35mdog.jpg\u001b[0m\r\n",
      "-rw-rw-r-- 1 cesare cesare   141886  三  27 15:21 \u001b[01;35meagle.jpg\u001b[0m\r\n",
      "-rwxr-xr-x 1 cesare cesare       94  三  25 10:17 \u001b[01;32mflow\u001b[0m*\r\n",
      "-rw-r--r-- 1 cesare cesare      135  三  22 16:58 labels20c.txt\r\n",
      "-rw-r--r-- 1 cesare cesare       21  三  21 17:32 labels3c.txt\r\n",
      "-rw-r--r-- 1 cesare cesare       15  三  28 09:48 labels_fidget.txt\r\n",
      "-rw-r--r-- 1 cesare cesare       27  三  21 17:32 labels_o.txt\r\n",
      "-rw-r--r-- 1 cesare cesare       15  三  30 15:16 labels.txt\r\n",
      "-rw-rw-r-- 1 cesare cesare    35141  三  25 10:17 LICENSE\r\n",
      "-rw-rw-r-- 1 cesare cesare     5686  三  30 10:55 \u001b[01;35moutput.avi\u001b[0m\r\n",
      "-rw-rw-r-- 1 cesare cesare   283380  三  25 10:17 \u001b[01;35mpreview.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 cesare cesare    11539  三  25 10:17 README.md\r\n",
      "drwxrwxr-x 3 cesare cesare     4096  三  26 13:11 \u001b[01;34msample_img\u001b[0m/\r\n",
      "-rw-rw-r-- 1 cesare cesare     2575  三  25 10:17 setup.py\r\n",
      "drwxrwxr-x 3 cesare cesare     4096  三  25 10:17 \u001b[01;34mtest\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cesare/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "\n",
      "Example usage: flow --imgdir sample_img/ --model cfg/yolo.cfg --load bin/yolo.weights\n",
      "\n",
      "Arguments:\n",
      "  --dataset        path to dataset directory\n",
      "  --labels         path to labels file\n",
      "  --threshold      detection threshold\n",
      "  --batch          batch size\n",
      "  --model          configuration of choice\n",
      "  --train          train the whole net\n",
      "  --annotation     path to annotation directory\n",
      "  --save           save checkpoint every ? training examples\n",
      "  --backup         path to backup folder\n",
      "  --savepb         save net and weight to a .pb file\n",
      "  --load           how to initialize the net? Either from .weights or a checkpoint, or even from scratch\n",
      "  --config         path to .cfg directory\n",
      "  --saveVideo      Records video from input video or camera\n",
      "  --gpu            how much gpu (from 0.0 to 1.0)\n",
      "  --binary         path to .weights directory\n",
      "  --summary        path to TensorBoard summaries directory\n",
      "  --keep           Number of most recent training results to save\n",
      "  --queue          process demo in batch\n",
      "  --json           Outputs bounding box information in json format.\n",
      "  --pbLoad         path to .pb protobuf file (metaLoad must also be specified)\n",
      "  --demo           demo on webcam\n",
      "  --help, --h, -h  show this super helpful message and exit\n",
      "  --trainer        training algorithm\n",
      "  --gpuName        GPU device name\n",
      "  --metaLoad       path to .meta file generated during --savepb that corresponds to .pb file\n",
      "  --momentum       applicable for rmsprop and momentum optimizers\n",
      "  --verbalise      say out loud while building graph\n",
      "  --epoch          number of epoch\n",
      "  --imgdir         path to testing directory with images\n",
      "  --lr             learning rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./flow --h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cesare/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "\n",
      "Parsing ./cfg/tiny-yolo-voc.cfg\n",
      "Parsing cfg/tiny-yolo-voc-1c.cfg\n",
      "Loading bin/tiny-yolo-voc.weights ...\n",
      "Successfully identified 63471556 bytes\n",
      "Finished in 0.015154361724853516s\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "cfg/tiny-yolo-voc-1c.cfg loss hyper-parameters:\n",
      "\tH       = 13\n",
      "\tW       = 13\n",
      "\tbox     = 5\n",
      "\tclasses = 1\n",
      "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
      "Building cfg/tiny-yolo-voc-1c.cfg loss\n",
      "Building cfg/tiny-yolo-voc-1c.cfg train op\n",
      "2018-03-30 15:26:33.485641: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "Finished in 3.4399497509002686s\n",
      "\n",
      "Enter training ...\n",
      "\n",
      "cfg/tiny-yolo-voc-1c.cfg parsing ../../Documents/annotations/\n",
      "Parsing for ['fidget_spinner'] \n",
      "[====================>]100%  000043.xml\n",
      "Statistics:\n",
      "fidget_spinner: 101\n",
      "Dataset size: 60\n",
      "Dataset of 60 instance(s)\n",
      "Training statistics: \n",
      "\tLearning rate : 1e-05\n",
      "\tBatch size    : 16\n",
      "\tEpoch number  : 50\n",
      "\tBackup every  : 2000\n",
      "step 1 - loss 107.06622314453125 - moving ave loss 107.06622314453125\n",
      "step 2 - loss 106.68447875976562 - moving ave loss 107.02804870605469\n",
      "step 3 - loss 106.36546325683594 - moving ave loss 106.96179016113283\n",
      "Finish 1 epoch(es)\n",
      "step 4 - loss 105.50814056396484 - moving ave loss 106.81642520141604\n",
      "step 5 - loss 104.59593200683594 - moving ave loss 106.59437588195803\n",
      "step 6 - loss 104.23068237304688 - moving ave loss 106.35800653106692\n",
      "Finish 2 epoch(es)\n",
      "step 7 - loss 103.697998046875 - moving ave loss 106.09200568264774\n",
      "step 8 - loss 102.93324279785156 - moving ave loss 105.77612939416812\n",
      "step 9 - loss 102.52056884765625 - moving ave loss 105.45057333951694\n",
      "Finish 3 epoch(es)\n",
      "step 10 - loss 101.92784881591797 - moving ave loss 105.09830088715705\n",
      "step 11 - loss 101.69587707519531 - moving ave loss 104.75805850596089\n",
      "step 12 - loss 101.01499938964844 - moving ave loss 104.38375259432965\n",
      "Finish 4 epoch(es)\n",
      "step 13 - loss 100.61833190917969 - moving ave loss 104.00721052581466\n",
      "step 14 - loss 99.6829833984375 - moving ave loss 103.57478781307695\n",
      "step 15 - loss 99.84209442138672 - moving ave loss 103.20151847390794\n",
      "Finish 5 epoch(es)\n",
      "step 16 - loss 99.100341796875 - moving ave loss 102.79140080620465\n",
      "step 17 - loss 98.24136352539062 - moving ave loss 102.33639707812324\n",
      "step 18 - loss 98.04013061523438 - moving ave loss 101.90677043183436\n",
      "Finish 6 epoch(es)\n",
      "step 19 - loss 97.26737976074219 - moving ave loss 101.44283136472515\n",
      "step 20 - loss 97.18616485595703 - moving ave loss 101.01716471384835\n",
      "step 21 - loss 96.49232482910156 - moving ave loss 100.56468072537368\n",
      "Finish 7 epoch(es)\n",
      "step 22 - loss 95.89230346679688 - moving ave loss 100.09744299951599\n",
      "step 23 - loss 95.86458587646484 - moving ave loss 99.67415728721089\n",
      "step 24 - loss 94.77916717529297 - moving ave loss 99.18465827601909\n",
      "Finish 8 epoch(es)\n",
      "step 25 - loss 94.59870910644531 - moving ave loss 98.72606335906171\n",
      "step 26 - loss 93.60911560058594 - moving ave loss 98.21436858321414\n",
      "step 27 - loss 93.95870971679688 - moving ave loss 97.78880269657242\n",
      "Finish 9 epoch(es)\n",
      "step 28 - loss 92.72340393066406 - moving ave loss 97.28226281998158\n",
      "step 29 - loss 92.951904296875 - moving ave loss 96.84922696767092\n",
      "step 30 - loss 92.4320068359375 - moving ave loss 96.40750495449758\n",
      "Finish 10 epoch(es)\n",
      "step 31 - loss 92.13597106933594 - moving ave loss 95.98035156598142\n",
      "step 32 - loss 91.57072448730469 - moving ave loss 95.53938885811375\n",
      "step 33 - loss 90.47879791259766 - moving ave loss 95.03332976356214\n",
      "Finish 11 epoch(es)\n",
      "step 34 - loss 90.33656311035156 - moving ave loss 94.56365309824109\n",
      "step 35 - loss 89.83905029296875 - moving ave loss 94.09119281771386\n",
      "step 36 - loss 88.88896179199219 - moving ave loss 93.5709697151417\n",
      "Finish 12 epoch(es)\n",
      "step 37 - loss 90.14060974121094 - moving ave loss 93.22793371774863\n",
      "step 38 - loss 88.56423950195312 - moving ave loss 92.76156429616907\n",
      "step 39 - loss 87.66976165771484 - moving ave loss 92.25238403232365\n",
      "Finish 13 epoch(es)\n",
      "step 40 - loss 87.36546325683594 - moving ave loss 91.76369195477487\n",
      "step 41 - loss 87.34765625 - moving ave loss 91.32208838429737\n",
      "step 42 - loss 86.3597412109375 - moving ave loss 90.8258536669614\n",
      "Finish 14 epoch(es)\n",
      "step 43 - loss 86.2264633178711 - moving ave loss 90.36591463205237\n",
      "step 44 - loss 86.28175354003906 - moving ave loss 89.95749852285103\n",
      "step 45 - loss 85.33509826660156 - moving ave loss 89.49525849722608\n",
      "Finish 15 epoch(es)\n",
      "step 46 - loss 84.05210876464844 - moving ave loss 88.95094352396832\n",
      "step 47 - loss 85.23323059082031 - moving ave loss 88.57917223065353\n",
      "step 48 - loss 84.70854187011719 - moving ave loss 88.1921091945999\n",
      "Finish 16 epoch(es)\n",
      "step 49 - loss 83.70339965820312 - moving ave loss 87.74323824096021\n",
      "step 50 - loss 83.3218994140625 - moving ave loss 87.30110435827045\n",
      "step 51 - loss 83.21064758300781 - moving ave loss 86.89205868074419\n",
      "Finish 17 epoch(es)\n",
      "step 52 - loss 81.32987976074219 - moving ave loss 86.335840788744\n",
      "step 53 - loss 82.16880798339844 - moving ave loss 85.91913750820945\n",
      "step 54 - loss 82.05394744873047 - moving ave loss 85.53261850226156\n",
      "Finish 18 epoch(es)\n",
      "step 55 - loss 80.73397827148438 - moving ave loss 85.05275447918385\n",
      "step 56 - loss 81.31211853027344 - moving ave loss 84.6786908842928\n",
      "step 57 - loss 79.48126220703125 - moving ave loss 84.15894801656665\n",
      "Finish 19 epoch(es)\n",
      "step 58 - loss 78.505126953125 - moving ave loss 83.5935659102225\n",
      "step 59 - loss 79.84550476074219 - moving ave loss 83.21875979527447\n",
      "step 60 - loss 79.09040069580078 - moving ave loss 82.80592388532709\n",
      "Finish 20 epoch(es)\n",
      "step 61 - loss 78.70504760742188 - moving ave loss 82.39583625753657\n",
      "step 62 - loss 77.86390686035156 - moving ave loss 81.94264331781808\n",
      "step 63 - loss 76.97718811035156 - moving ave loss 81.44609779707143\n",
      "Finish 21 epoch(es)\n",
      "step 64 - loss 75.99424743652344 - moving ave loss 80.90091276101664\n",
      "step 65 - loss 76.36428833007812 - moving ave loss 80.4472503179228\n",
      "step 66 - loss 77.66001892089844 - moving ave loss 80.16852717822036\n",
      "Finish 22 epoch(es)\n",
      "step 67 - loss 75.7381591796875 - moving ave loss 79.72549037836707\n",
      "step 68 - loss 75.50890350341797 - moving ave loss 79.30383169087217\n",
      "step 69 - loss 75.14643859863281 - moving ave loss 78.88809238164824\n",
      "Finish 23 epoch(es)\n",
      "step 70 - loss 75.17005920410156 - moving ave loss 78.51628906389357\n",
      "step 71 - loss 74.31554412841797 - moving ave loss 78.096214570346\n",
      "step 72 - loss 73.30821990966797 - moving ave loss 77.61741510427821\n",
      "Finish 24 epoch(es)\n",
      "step 73 - loss 72.54740142822266 - moving ave loss 77.11041373667265\n",
      "step 74 - loss 73.44772338867188 - moving ave loss 76.74414470187259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 75 - loss 72.8818588256836 - moving ave loss 76.35791611425368\n",
      "Finish 25 epoch(es)\n",
      "step 76 - loss 72.03254699707031 - moving ave loss 75.92537920253535\n",
      "step 77 - loss 72.29670715332031 - moving ave loss 75.56251199761385\n",
      "step 78 - loss 70.64823913574219 - moving ave loss 75.07108471142669\n",
      "Finish 26 epoch(es)\n",
      "step 79 - loss 69.45307922363281 - moving ave loss 74.5092841626473\n",
      "step 80 - loss 70.77346801757812 - moving ave loss 74.13570254814039\n",
      "step 81 - loss 70.98505401611328 - moving ave loss 73.82063769493769\n",
      "Finish 27 epoch(es)\n",
      "step 82 - loss 68.53939819335938 - moving ave loss 73.29251374477985\n",
      "step 83 - loss 69.51333618164062 - moving ave loss 72.91459598846593\n",
      "step 84 - loss 69.62100982666016 - moving ave loss 72.58523737228536\n",
      "Finish 28 epoch(es)\n",
      "step 85 - loss 69.88368225097656 - moving ave loss 72.31508186015449\n",
      "step 86 - loss 68.52034759521484 - moving ave loss 71.93560843366053\n",
      "step 87 - loss 66.88948059082031 - moving ave loss 71.43099564937651\n",
      "Finish 29 epoch(es)\n",
      "step 88 - loss 65.3117904663086 - moving ave loss 70.81907513106972\n",
      "step 89 - loss 67.71743774414062 - moving ave loss 70.50891139237682\n",
      "step 90 - loss 66.54244995117188 - moving ave loss 70.11226524825632\n",
      "Finish 30 epoch(es)\n",
      "step 91 - loss 65.5445556640625 - moving ave loss 69.65549428983694\n",
      "step 92 - loss 63.02655792236328 - moving ave loss 68.99260065308957\n",
      "step 93 - loss 66.06069946289062 - moving ave loss 68.69941053406967\n",
      "Finish 31 epoch(es)\n",
      "step 94 - loss 65.69944763183594 - moving ave loss 68.3994142438463\n",
      "step 95 - loss 61.619407653808594 - moving ave loss 67.72141358484252\n",
      "step 96 - loss 64.01023864746094 - moving ave loss 67.35029609110437\n",
      "Finish 32 epoch(es)\n",
      "step 97 - loss 63.33026885986328 - moving ave loss 66.94829336798026\n",
      "step 98 - loss 63.53894805908203 - moving ave loss 66.60735883709043\n",
      "step 99 - loss 59.55640411376953 - moving ave loss 65.90226336475834\n",
      "Finish 33 epoch(es)\n",
      "step 100 - loss 63.353599548339844 - moving ave loss 65.6473969831165\n",
      "step 101 - loss 59.317626953125 - moving ave loss 65.01441998011734\n",
      "step 102 - loss 62.58580017089844 - moving ave loss 64.77155799919545\n",
      "Finish 34 epoch(es)\n",
      "step 103 - loss 61.512794494628906 - moving ave loss 64.4456816487388\n",
      "step 104 - loss 57.838111877441406 - moving ave loss 63.78492467160906\n",
      "step 105 - loss 61.115516662597656 - moving ave loss 63.51798387070792\n",
      "Finish 35 epoch(es)\n",
      "step 106 - loss 58.82322311401367 - moving ave loss 63.048507795038496\n",
      "step 107 - loss 60.820640563964844 - moving ave loss 62.82572107193113\n",
      "step 108 - loss 57.04174041748047 - moving ave loss 62.24732300648606\n",
      "Finish 36 epoch(es)\n",
      "step 109 - loss 55.784751892089844 - moving ave loss 61.601065895046446\n",
      "step 110 - loss 57.537933349609375 - moving ave loss 61.19475264050274\n",
      "step 111 - loss 58.447364807128906 - moving ave loss 60.92001385716536\n",
      "Finish 37 epoch(es)\n",
      "step 112 - loss 56.844398498535156 - moving ave loss 60.51245232130234\n",
      "step 113 - loss 57.23720932006836 - moving ave loss 60.18492802117894\n",
      "step 114 - loss 59.486961364746094 - moving ave loss 60.11513135553566\n",
      "Finish 38 epoch(es)\n",
      "step 115 - loss 54.69984436035156 - moving ave loss 59.57360265601725\n",
      "step 116 - loss 55.04416275024414 - moving ave loss 59.12065866543995\n",
      "step 117 - loss 57.0034294128418 - moving ave loss 58.90893574018014\n",
      "Finish 39 epoch(es)\n",
      "step 118 - loss 54.2095947265625 - moving ave loss 58.439001638818375\n",
      "step 119 - loss 55.688777923583984 - moving ave loss 58.16397926729494\n",
      "step 120 - loss 53.89624786376953 - moving ave loss 57.737206126942404\n",
      "Finish 40 epoch(es)\n",
      "step 121 - loss 52.97383499145508 - moving ave loss 57.26086901339367\n",
      "step 122 - loss 54.48653793334961 - moving ave loss 56.98343590538927\n",
      "step 123 - loss 54.131874084472656 - moving ave loss 56.69827972329761\n",
      "Finish 41 epoch(es)\n",
      "step 124 - loss 57.0095100402832 - moving ave loss 56.729402754996165\n",
      "step 125 - loss 51.10391616821289 - moving ave loss 56.16685409631784\n",
      "Checkpoint at step 125\n",
      "step 126 - loss 52.447898864746094 - moving ave loss 55.79495857316067\n",
      "Finish 42 epoch(es)\n",
      "step 127 - loss 49.367828369140625 - moving ave loss 55.152245552758664\n",
      "step 128 - loss 52.740882873535156 - moving ave loss 54.911109284836314\n",
      "step 129 - loss 51.62152099609375 - moving ave loss 54.582150455962065\n",
      "Finish 43 epoch(es)\n",
      "step 130 - loss 48.15257263183594 - moving ave loss 53.93919267354946\n",
      "step 131 - loss 50.273311614990234 - moving ave loss 53.57260456769353\n",
      "step 132 - loss 53.92430877685547 - moving ave loss 53.60777498860973\n",
      "Finish 44 epoch(es)\n",
      "step 133 - loss 50.90363693237305 - moving ave loss 53.337361182986065\n",
      "step 134 - loss 50.32271957397461 - moving ave loss 53.035897022084924\n",
      "step 135 - loss 46.34818649291992 - moving ave loss 52.36712596916843\n",
      "Finish 45 epoch(es)\n",
      "step 136 - loss 47.499542236328125 - moving ave loss 51.8803675958844\n",
      "step 137 - loss 53.52928924560547 - moving ave loss 52.04525976085651\n",
      "step 138 - loss 46.538055419921875 - moving ave loss 51.49453932676305\n",
      "Finish 46 epoch(es)\n",
      "step 139 - loss 49.4127197265625 - moving ave loss 51.286357366743\n",
      "step 140 - loss 48.275054931640625 - moving ave loss 50.98522712323276\n",
      "step 141 - loss 45.42481231689453 - moving ave loss 50.42918564259894\n",
      "Finish 47 epoch(es)\n",
      "step 142 - loss 45.13756561279297 - moving ave loss 49.90002363961834\n",
      "step 143 - loss 48.89902114868164 - moving ave loss 49.79992339052467\n",
      "step 144 - loss 43.911476135253906 - moving ave loss 49.21107866499759\n",
      "Finish 48 epoch(es)\n",
      "step 145 - loss 47.931785583496094 - moving ave loss 49.08314935684744\n",
      "step 146 - loss 44.13750457763672 - moving ave loss 48.58858487892637\n",
      "step 147 - loss 44.96918487548828 - moving ave loss 48.22664487858256\n",
      "Finish 49 epoch(es)\n",
      "step 148 - loss 42.75172424316406 - moving ave loss 47.679152815040716\n",
      "step 149 - loss 43.61426544189453 - moving ave loss 47.2726640777261\n",
      "step 150 - loss 45.743247985839844 - moving ave loss 47.119722468537475\n",
      "Finish 50 epoch(es)\n",
      "Checkpoint at step 150\n",
      "Training finished, exit.\n"
     ]
    }
   ],
   "source": [
    "!./flow --model cfg/tiny-yolo-voc-1c.cfg --load bin/tiny-yolo-voc.weights --train --annotation \"../../Documents/annotations/\" --dataset \"../../Documents/images/\" --epoch 50 --trainer adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
