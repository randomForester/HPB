{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run a YOLO_v3 style detection model on test images.\n",
    "\"\"\"\n",
    "\n",
    "import colorsys\n",
    "import os\n",
    "import random\n",
    "from timeit import time\n",
    "from timeit import default_timer as timer  ### to calculate FPS\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval\n",
    "from yolo3.utils import letterbox_image\n",
    "\n",
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "        self.model_path = 'model_data/yolo.h5'\n",
    "        self.anchors_path = 'model_data/yolo_anchors.txt'\n",
    "        self.classes_path = 'model_data/coco_classes.txt'\n",
    "        self.score = 0.3\n",
    "        self.iou = 0.5\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.model_image_size = (416, 416) # fixed size or (None, None)\n",
    "        self.is_fixed_size = self.model_image_size != (None, None)\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "            anchors = [float(x) for x in anchors.split(',')]\n",
    "            anchors = np.array(anchors).reshape(-1, 2)\n",
    "        return anchors\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "\n",
    "        self.yolo_model = load_model(model_path, compile=False)\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        #random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        random.seed(229)  # Fixed seed for consistent colors across runs.\n",
    "        random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = time.time()\n",
    "        count = 0\n",
    "\n",
    "        if self.is_fixed_size:\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        #print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            #label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            label = '{}, {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            with open('outputEis.txt', 'a') as f:\n",
    "            #with open('outputEis.csv', 'a') as f:\n",
    "                #print(label, (left, top), (right, bottom))\n",
    "                #print(\"{}, {}, {}, {}, {}\".format(label, left, top, right, bottom))\n",
    "                print(\"{}, {}, {}, {}, {}, {}\".format(count - 1, label, left, top, right, bottom), file=f)\n",
    "                #print(\"{}, {}, {}, {}, {}, {}\".format(len(out_boxes), label, left, top, right, bottom), file=f)\n",
    "            #f.close()\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "\n",
    "        end = time.time()\n",
    "        #print(end - start)\n",
    "        return image\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(yolo, video_path):\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    print(\"Video Dim: {}  {}  {}\".format(vid.get(3), 'X', vid.get(4)))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    #out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (1920,1080))\n",
    "    out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (960,540))      # resize image half\n",
    "    \n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    start4Total = timer()\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        \n",
    "        if return_value == True:\n",
    "        \n",
    "            cnt += 1\n",
    "            # Re-size\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # resize image half\n",
    "            # Re-size\n",
    "            image = Image.fromarray(frame)\n",
    "            image = yolo.detect_image(image)\n",
    "            result = np.asarray(image)\n",
    "            curr_time = timer()\n",
    "            exec_time = curr_time - prev_time\n",
    "            prev_time = curr_time\n",
    "            accum_time = accum_time + exec_time\n",
    "            curr_fps = curr_fps + 1\n",
    "            if accum_time > 1:\n",
    "                accum_time = accum_time - 1\n",
    "                fps = \"FPS: \" + str(curr_fps)\n",
    "                curr_fps = 0\n",
    "            \n",
    "            print(cnt-1)\n",
    "            \n",
    "            cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
    "            cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "            out.write(result)\n",
    "            cv2.imshow(\"result\", result)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print('++++++++ Video End ++++++++')\n",
    "    \n",
    "    vid.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print('\\nTotal elapsed time = ' + str(timer() - start4Total) + ' s\\n')\n",
    "\n",
    "    #yolo.close_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(yolo, video_path):\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    print(\"Video Dim: {}  {}  {}\".format(vid.get(3), 'X', vid.get(4)))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (1920,1080))\n",
    "    #out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (960,540))      # resize image half\n",
    "    i = 0\n",
    "    frame_rate_divider = 3\n",
    "    \n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    start4Total = timer()\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        \n",
    "        if return_value == True:\n",
    "            if i % frame_rate_divider == 0:\n",
    "                \n",
    "                cnt += 1\n",
    "                # Re-size\n",
    "                #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # resize image half\n",
    "                # Re-size\n",
    "                image = Image.fromarray(frame)\n",
    "                image = yolo.detect_image(image)\n",
    "                result = np.asarray(image)\n",
    "                curr_time = timer()\n",
    "                exec_time = curr_time - prev_time\n",
    "                prev_time = curr_time\n",
    "                accum_time = accum_time + exec_time\n",
    "                curr_fps = curr_fps + 1\n",
    "                if accum_time > 1:\n",
    "                    accum_time = accum_time - 1\n",
    "                    fps = \"FPS: \" + str(curr_fps)\n",
    "                    curr_fps = 0\n",
    "            \n",
    "                print(cnt-1)\n",
    "            \n",
    "                cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
    "                cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "                out.write(result)\n",
    "                cv2.imshow(\"result\", result)\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "                \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print('++++++++ Video End ++++++++')\n",
    "    \n",
    "    vid.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print('\\nTotal elapsed time = ' + str(timer() - start4Total) + ' s\\n')\n",
    "\n",
    "    #yolo.close_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data/yolo.h5 model, anchors, and classes loaded.\n",
      "Video Dim: 1920.0  X  1080.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "++++++++ Video End ++++++++\n",
      "\n",
      "Total elapsed time = 14.412281831959262 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from yolo import YOLO\n",
    "#from yolo import detect_video\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_path='/media/cfchen/956df7bc-562e-4f24-8339-fd0b67f98888/Downloaded/VideosHPB/IMAG0011.mp4'\n",
    "    #video_path='/media/cfchen/956df7bc-562e-4f24-8339-fd0b67f98888/Downloaded/VideosHPB/peoplecars.mp4'\n",
    "    detect_video(YOLO(), video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
