{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import time\n",
    "from time import time as timer\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cfchen/Github36/Mask_RCNN-master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfchen/anaconda3/envs/MaskRCNN/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#import random\n",
    "#import math\n",
    "#import numpy as np\n",
    "#import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print(ROOT_DIR)\n",
    "    \n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "import mrcnn.utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "/home/cfchen/Github36/Mask_RCNN-master\n"
     ]
    }
   ],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "## Directory of images to run detection on\n",
    "#IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "    \n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "    \n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cfchen/Github36/Mask_RCNN-master\n"
     ]
    }
   ],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    np.random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "colors = random_colors(len(class_names))\n",
    "class_dict = {\n",
    "    name: color for name, color in zip(class_names, colors)\n",
    "}\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Dim: 1920.0  X  1080.0\n",
      "Frame Number 0: Found 8 boxes for img\n",
      "Frame Number 1: Found 9 boxes for img\n",
      "Frame Number 2: Found 11 boxes for img\n",
      "Frame Number 3: Found 11 boxes for img\n",
      "Frame Number 4: Found 10 boxes for img\n",
      "Frame Number 5: Found 7 boxes for img\n",
      "Frame Number 6: Found 10 boxes for img\n",
      "Frame Number 7: Found 11 boxes for img\n",
      "Frame Number 8: Found 8 boxes for img\n",
      "Frame Number 9: Found 10 boxes for img\n",
      "Frame Number 10: Found 8 boxes for img\n",
      "Frame Number 11: Found 8 boxes for img\n",
      "Frame Number 12: Found 8 boxes for img\n",
      "Frame Number 13: Found 7 boxes for img\n",
      "Frame Number 14: Found 9 boxes for img\n",
      "Frame Number 15: Found 9 boxes for img\n",
      "Frame Number 16: Found 9 boxes for img\n",
      "Frame Number 17: Found 8 boxes for img\n",
      "Frame Number 18: Found 8 boxes for img\n",
      "Frame Number 19: Found 9 boxes for img\n",
      "Frame Number 20: Found 8 boxes for img\n",
      "Frame Number 21: Found 9 boxes for img\n",
      "Frame Number 22: Found 10 boxes for img\n",
      "Frame Number 23: Found 9 boxes for img\n",
      "Frame Number 24: Found 12 boxes for img\n",
      "Frame Number 25: Found 11 boxes for img\n",
      "Frame Number 26: Found 10 boxes for img\n",
      "Frame Number 27: Found 11 boxes for img\n",
      "Frame Number 28: Found 9 boxes for img\n",
      "Frame Number 29: Found 9 boxes for img\n",
      "Frame Number 30: Found 9 boxes for img\n",
      "Frame Number 31: Found 11 boxes for img\n",
      "Frame Number 32: Found 9 boxes for img\n",
      "Frame Number 33: Found 8 boxes for img\n",
      "Frame Number 34: Found 8 boxes for img\n",
      "Frame Number 35: Found 7 boxes for img\n",
      "Frame Number 36: Found 10 boxes for img\n",
      "Frame Number 37: Found 11 boxes for img\n",
      "Frame Number 38: Found 11 boxes for img\n",
      "Frame Number 39: Found 9 boxes for img\n",
      "Frame Number 40: Found 10 boxes for img\n",
      "Frame Number 41: Found 10 boxes for img\n",
      "Frame Number 42: Found 12 boxes for img\n",
      "Frame Number 43: Found 11 boxes for img\n",
      "Frame Number 44: Found 9 boxes for img\n",
      "Frame Number 45: Found 9 boxes for img\n",
      "Frame Number 46: Found 10 boxes for img\n",
      "Frame Number 47: Found 9 boxes for img\n",
      "Frame Number 48: Found 9 boxes for img\n",
      "Frame Number 49: Found 10 boxes for img\n",
      "Frame Number 50: Found 10 boxes for img\n",
      "Frame Number 51: Found 12 boxes for img\n",
      "Frame Number 52: Found 11 boxes for img\n",
      "Frame Number 53: Found 10 boxes for img\n",
      "Frame Number 54: Found 11 boxes for img\n",
      "Frame Number 55: Found 11 boxes for img\n",
      "Frame Number 56: Found 12 boxes for img\n",
      "Frame Number 57: Found 11 boxes for img\n",
      "Frame Number 58: Found 11 boxes for img\n",
      "Frame Number 59: Found 10 boxes for img\n",
      "Frame Number 60: Found 11 boxes for img\n",
      "Frame Number 61: Found 10 boxes for img\n",
      "Frame Number 62: Found 12 boxes for img\n",
      "Frame Number 63: Found 12 boxes for img\n",
      "Frame Number 64: Found 12 boxes for img\n",
      "Frame Number 65: Found 12 boxes for img\n",
      "Frame Number 66: Found 13 boxes for img\n",
      "Frame Number 67: Found 12 boxes for img\n",
      "Frame Number 68: Found 11 boxes for img\n",
      "Frame Number 69: Found 11 boxes for img\n",
      "Frame Number 70: Found 10 boxes for img\n",
      "Frame Number 71: Found 12 boxes for img\n",
      "Frame Number 72: Found 13 boxes for img\n",
      "Frame Number 73: Found 14 boxes for img\n",
      "Frame Number 74: Found 13 boxes for img\n",
      "Frame Number 75: Found 13 boxes for img\n",
      "Frame Number 76: Found 13 boxes for img\n",
      "Frame Number 77: Found 13 boxes for img\n",
      "Frame Number 78: Found 13 boxes for img\n",
      "Frame Number 79: Found 14 boxes for img\n",
      "Frame Number 80: Found 12 boxes for img\n",
      "Frame Number 81: Found 12 boxes for img\n",
      "Frame Number 82: Found 11 boxes for img\n",
      "Frame Number 83: Found 11 boxes for img\n",
      "Frame Number 84: Found 10 boxes for img\n",
      "Frame Number 85: Found 10 boxes for img\n",
      "Frame Number 86: Found 10 boxes for img\n",
      "Frame Number 87: Found 11 boxes for img\n",
      "Frame Number 88: Found 10 boxes for img\n",
      "Frame Number 89: Found 10 boxes for img\n",
      "Frame Number 90: Found 12 boxes for img\n",
      "Frame Number 91: Found 12 boxes for img\n",
      "Frame Number 92: Found 11 boxes for img\n",
      "Frame Number 93: Found 11 boxes for img\n",
      "Frame Number 94: Found 11 boxes for img\n",
      "Frame Number 95: Found 9 boxes for img\n",
      "Frame Number 96: Found 13 boxes for img\n",
      "Frame Number 97: Found 12 boxes for img\n",
      "Frame Number 98: Found 13 boxes for img\n",
      "Frame Number 99: Found 11 boxes for img\n",
      "Frame Number 100: Found 10 boxes for img\n",
      "Frame Number 101: Found 10 boxes for img\n",
      "Frame Number 102: Found 12 boxes for img\n",
      "Frame Number 103: Found 12 boxes for img\n",
      "Frame Number 104: Found 11 boxes for img\n",
      "Frame Number 105: Found 13 boxes for img\n",
      "Frame Number 106: Found 12 boxes for img\n",
      "Frame Number 107: Found 11 boxes for img\n",
      "Frame Number 108: Found 12 boxes for img\n",
      "Frame Number 109: Found 12 boxes for img\n",
      "Frame Number 110: Found 12 boxes for img\n",
      "Frame Number 111: Found 11 boxes for img\n",
      "Frame Number 112: Found 11 boxes for img\n",
      "Frame Number 113: Found 12 boxes for img\n",
      "Frame Number 114: Found 11 boxes for img\n",
      "Frame Number 115: Found 9 boxes for img\n",
      "Frame Number 116: Found 10 boxes for img\n",
      "Frame Number 117: Found 11 boxes for img\n",
      "Frame Number 118: Found 10 boxes for img\n",
      "Frame Number 119: Found 10 boxes for img\n",
      "Frame Number 120: Found 12 boxes for img\n",
      "Frame Number 121: Found 12 boxes for img\n",
      "Frame Number 122: Found 13 boxes for img\n",
      "Frame Number 123: Found 12 boxes for img\n",
      "Frame Number 124: Found 12 boxes for img\n",
      "Frame Number 125: Found 13 boxes for img\n",
      "Frame Number 126: Found 12 boxes for img\n",
      "Frame Number 127: Found 12 boxes for img\n",
      "Frame Number 128: Found 11 boxes for img\n",
      "Frame Number 129: Found 9 boxes for img\n",
      "Frame Number 130: Found 9 boxes for img\n",
      "Frame Number 131: Found 9 boxes for img\n",
      "Frame Number 132: Found 9 boxes for img\n",
      "Frame Number 133: Found 9 boxes for img\n",
      "Frame Number 134: Found 10 boxes for img\n",
      "Frame Number 135: Found 8 boxes for img\n",
      "Frame Number 136: Found 10 boxes for img\n",
      "Frame Number 137: Found 10 boxes for img\n",
      "Frame Number 138: Found 9 boxes for img\n",
      "Frame Number 139: Found 9 boxes for img\n",
      "Frame Number 140: Found 9 boxes for img\n",
      "Frame Number 141: Found 10 boxes for img\n",
      "Frame Number 142: Found 10 boxes for img\n",
      "Frame Number 143: Found 9 boxes for img\n",
      "Frame Number 144: Found 8 boxes for img\n",
      "Frame Number 145: Found 8 boxes for img\n",
      "Frame Number 146: Found 8 boxes for img\n",
      "Frame Number 147: Found 7 boxes for img\n",
      "Frame Number 148: Found 9 boxes for img\n",
      "Frame Number 149: Found 10 boxes for img\n",
      "Frame Number 150: Found 8 boxes for img\n",
      "Frame Number 151: Found 8 boxes for img\n",
      "Frame Number 152: Found 9 boxes for img\n",
      "Frame Number 153: Found 9 boxes for img\n",
      "Frame Number 154: Found 10 boxes for img\n",
      "Frame Number 155: Found 10 boxes for img\n",
      "Frame Number 156: Found 10 boxes for img\n",
      "Frame Number 157: Found 9 boxes for img\n",
      "Frame Number 158: Found 11 boxes for img\n",
      "Frame Number 159: Found 10 boxes for img\n",
      "Frame Number 160: Found 9 boxes for img\n",
      "Frame Number 161: Found 10 boxes for img\n",
      "Frame Number 162: Found 10 boxes for img\n",
      "Frame Number 163: Found 10 boxes for img\n",
      "Frame Number 164: Found 10 boxes for img\n",
      "Frame Number 165: Found 10 boxes for img\n",
      "Frame Number 166: Found 9 boxes for img\n",
      "Frame Number 167: Found 10 boxes for img\n",
      "Frame Number 168: Found 9 boxes for img\n",
      "Frame Number 169: Found 8 boxes for img\n",
      "Frame Number 170: Found 8 boxes for img\n",
      "Frame Number 171: Found 8 boxes for img\n",
      "Frame Number 172: Found 8 boxes for img\n",
      "Frame Number 173: Found 8 boxes for img\n",
      "Frame Number 174: Found 7 boxes for img\n",
      "Frame Number 175: Found 8 boxes for img\n",
      "Frame Number 176: Found 9 boxes for img\n",
      "Frame Number 177: Found 9 boxes for img\n",
      "Frame Number 178: Found 9 boxes for img\n",
      "Frame Number 179: Found 9 boxes for img\n",
      "Frame Number 180: Found 8 boxes for img\n",
      "Frame Number 181: Found 8 boxes for img\n",
      "Frame Number 182: Found 8 boxes for img\n",
      "Frame Number 183: Found 8 boxes for img\n",
      "Frame Number 184: Found 8 boxes for img\n",
      "Frame Number 185: Found 9 boxes for img\n",
      "Frame Number 186: Found 10 boxes for img\n",
      "Frame Number 187: Found 10 boxes for img\n",
      "Frame Number 188: Found 8 boxes for img\n",
      "Frame Number 189: Found 8 boxes for img\n",
      "Frame Number 190: Found 8 boxes for img\n",
      "Frame Number 191: Found 9 boxes for img\n",
      "Frame Number 192: Found 9 boxes for img\n",
      "Frame Number 193: Found 9 boxes for img\n",
      "Frame Number 194: Found 10 boxes for img\n",
      "Frame Number 195: Found 10 boxes for img\n",
      "Frame Number 196: Found 9 boxes for img\n",
      "Frame Number 197: Found 8 boxes for img\n",
      "Frame Number 198: Found 8 boxes for img\n",
      "Frame Number 199: Found 8 boxes for img\n",
      "Frame Number 200: Found 9 boxes for img\n",
      "Frame Number 201: Found 9 boxes for img\n",
      "Frame Number 202: Found 9 boxes for img\n",
      "Frame Number 203: Found 9 boxes for img\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Number 204: Found 8 boxes for img\n",
      "Frame Number 205: Found 9 boxes for img\n",
      "Frame Number 206: Found 9 boxes for img\n",
      "Frame Number 207: Found 7 boxes for img\n",
      "Frame Number 208: Found 8 boxes for img\n",
      "Frame Number 209: Found 8 boxes for img\n",
      "Frame Number 210: Found 8 boxes for img\n",
      "Frame Number 211: Found 9 boxes for img\n",
      "Frame Number 212: Found 9 boxes for img\n",
      "Frame Number 213: Found 9 boxes for img\n",
      "Frame Number 214: Found 10 boxes for img\n",
      "Frame Number 215: Found 9 boxes for img\n",
      "Frame Number 216: Found 6 boxes for img\n",
      "Frame Number 217: Found 6 boxes for img\n",
      "Frame Number 218: Found 6 boxes for img\n",
      "Frame Number 219: Found 6 boxes for img\n",
      "Frame Number 220: Found 7 boxes for img\n",
      "Frame Number 221: Found 7 boxes for img\n",
      "Frame Number 222: Found 9 boxes for img\n",
      "Frame Number 223: Found 7 boxes for img\n",
      "Frame Number 224: Found 7 boxes for img\n",
      "Frame Number 225: Found 6 boxes for img\n",
      "Frame Number 226: Found 6 boxes for img\n",
      "Frame Number 227: Found 5 boxes for img\n",
      "Frame Number 228: Found 8 boxes for img\n",
      "Frame Number 229: Found 7 boxes for img\n",
      "Frame Number 230: Found 6 boxes for img\n",
      "Frame Number 231: Found 8 boxes for img\n",
      "Frame Number 232: Found 10 boxes for img\n",
      "Frame Number 233: Found 9 boxes for img\n",
      "Frame Number 234: Found 9 boxes for img\n",
      "Frame Number 235: Found 9 boxes for img\n",
      "Frame Number 236: Found 8 boxes for img\n",
      "Frame Number 237: Found 7 boxes for img\n",
      "Frame Number 238: Found 8 boxes for img\n",
      "Frame Number 239: Found 7 boxes for img\n",
      "Frame Number 240: Found 9 boxes for img\n",
      "Frame Number 241: Found 7 boxes for img\n",
      "Frame Number 242: Found 9 boxes for img\n",
      "Frame Number 243: Found 5 boxes for img\n",
      "Frame Number 244: Found 8 boxes for img\n",
      "Frame Number 245: Found 9 boxes for img\n",
      "Frame Number 246: Found 9 boxes for img\n",
      "Frame Number 247: Found 9 boxes for img\n",
      "Frame Number 248: Found 9 boxes for img\n",
      "Frame Number 249: Found 6 boxes for img\n",
      "Frame Number 250: Found 8 boxes for img\n",
      "Frame Number 251: Found 8 boxes for img\n",
      "Frame Number 252: Found 7 boxes for img\n",
      "Frame Number 253: Found 9 boxes for img\n",
      "Frame Number 254: Found 8 boxes for img\n",
      "Frame Number 255: Found 6 boxes for img\n",
      "Frame Number 256: Found 9 boxes for img\n",
      "Frame Number 257: Found 10 boxes for img\n",
      "Frame Number 258: Found 8 boxes for img\n",
      "Frame Number 259: Found 8 boxes for img\n",
      "++++++++ Video End ++++++++\n",
      "\n",
      "Total elapsed time = 82.68303513526917 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    #print(n_instances)\n",
    "    print('Frame Number {}: Found {} boxes for {}'.format(count - 1, n_instances, 'img'))\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i in range(n_instances):\n",
    "        '''\n",
    "        Detect Only Person\n",
    "        '''\n",
    "                \n",
    "        #if ids[i] != 1:        \n",
    "        #if ids[i] != 8 and ids[i] != 1 and ids[i] != 6 and ids[i] != 59:\n",
    "        #    continue\n",
    "        \n",
    "        if (scores[i] <= 0.7) or (ids[i] != 8 and ids[i] != 1 and ids[i] != 6):\n",
    "            continue\n",
    "        \n",
    "        '''\n",
    "        Detect Only Person\n",
    "        '''        \n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        color = class_dict[label]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        #image = cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255,0), 5)\n",
    "        #image = cv2.putText(image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2)\n",
    "        image = cv2.putText(image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        '''\n",
    "        #print(n_instances)\n",
    "        TLBR = '{} {} {} {}'.format(x1, y1, x2, y2)\n",
    "        captionLaIdSc = '{} {} {:.2f}'.format(label, ids[i], score) if score else label        \n",
    "        print(\"{}  {}  {}\".format(count - 1 , captionLaIdSc, TLBR))\n",
    "        #print(ids)\n",
    "        #print(ids[i])\n",
    "        '''\n",
    "        #print(n_instances)\n",
    "        \n",
    "        #with open('outputEis.txt', 'a') as f:\n",
    "        with open('outputEis.csv', 'a') as f:\n",
    "            TLBR = '{}, {}, {}, {}'.format(x1, y1, x2, y2)\n",
    "            captionLaIdSc = '{}, {}, {:.2f},'.format(label, ids[i], score) if score else label\n",
    "            print(\"{},  {}  {}\".format(count - 1 , captionLaIdSc, TLBR), file=f)\n",
    "        #f.close()\n",
    "        \n",
    "    return image\n",
    "\n",
    "capture = cv2.VideoCapture('/media/cfchen/956df7bc-562e-4f24-8339-fd0b67f98888/Downloaded/VideosHPB/IMAG0011.mp4')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('temp.avi',fourcc, 30.0, (960, 540))     # resize image half\n",
    "\n",
    "print(\"Video Dim: {}  {}  {}\".format(capture.get(3), 'X', capture.get(4)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, frame = capture.read() \n",
    "    \n",
    "    if ret == True:\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # resize image half\n",
    "\n",
    "        results = model.detect([frame], verbose=0)\n",
    "\n",
    "        r = results[0]\n",
    "    \n",
    "        frame = display_instances(frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n",
    "\n",
    "        '''\n",
    "        print('Frame NO.    {}: Found {} boxes for {}'.format(count - 1, r['rois'].shape[0], 'img'))\n",
    "        #print('{}  {}  {}'.format(print(r['scores']), r['class_ids'], r['rois']))\n",
    "        #print(r['scores'])           # Confidence\n",
    "        #print(r['rois'])             # Bounding Boxes \n",
    "        #print(r['class_ids'])        # Class IDs        \n",
    "        '''\n",
    "        \n",
    "        out.write(frame)\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')) or (ret == False):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print('++++++++ Video End ++++++++')\n",
    "  \n",
    "capture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('\\nTotal elapsed time = ' + str(timer() - start) + ' s\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mAP @ IoU=50 on Batch of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "#dataset.image_info[1:3]\n",
    "\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_images)\n",
    "print(len(dataset.image_info[2]))\n",
    "print(dataset.image_info[2]['id'])\n",
    "print(dataset.image_info[2]['source'])\n",
    "print(dataset.image_info[2]['path'])\n",
    "print(dataset.image_info[2]['width'])\n",
    "print(dataset.image_info[2]['height'])\n",
    "#print(dataset.image_info[2]['annotations'])\n",
    "#print(dataset.image_info[2])\n",
    "print('')\n",
    "\n",
    "print(dataset.class_names[8])\n",
    "print(dataset.class_ids)\n",
    "print('')\n",
    "\n",
    "print(dataset.class_info[80])\n",
    "print(dataset.class_info[80]['source'])\n",
    "dataset.class_info[80]['name']\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
