{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run a YOLO_v3 style detection model on test images.\n",
    "\"\"\"\n",
    "\n",
    "import colorsys\n",
    "import os\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "\n",
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "        self.model_path = 'model_data/yolo.h5' # model path or trained weights path\n",
    "        self.anchors_path = 'model_data/yolo_anchors.txt'\n",
    "        self.classes_path = 'model_data/coco_classes.txt'\n",
    "        self.score = 0.3\n",
    "        self.iou = 0.5\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.model_image_size = (416, 416) # fixed size or (None, None), hw\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            \n",
    "            '''\n",
    "            if predicted_class != 'car, 3' and predicted_class != 'bus, 6':\n",
    "                continue            \n",
    "            '''\n",
    "                \n",
    "            if (score <= 0.5) or (predicted_class != 'car, 3' and predicted_class != 'truck, 8'):\n",
    "                continue\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "            with open('outputEis.txt', 'a') as f:\n",
    "                #print(label, (left, top), (right, bottom))\n",
    "                print(\"{}, {}, {}, {}, {}, {}\".format(len(out_boxes), label, left, top, right, bottom), file=f)\n",
    "            \n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "\n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        return image\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_video(yolo, video_path):\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    print(\"Video Dim: {}  {}  {}\".format(vid.get(3), 'X', vid.get(4)))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    #out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (1920,1080))\n",
    "    out = cv2.VideoWriter('test_python_yolo3.avi',fourcc, 30.0, (960,540))      # resize image half\n",
    "    \n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    start4Total = timer()\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        \n",
    "        if return_value == True:\n",
    "            \n",
    "            cnt += 1\n",
    "            # Re-size\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # resize image half\n",
    "            # Re-size\n",
    "        \n",
    "            image = Image.fromarray(frame)\n",
    "            image = yolo.detect_image(image)\n",
    "            result = np.asarray(image)\n",
    "            curr_time = timer()\n",
    "            exec_time = curr_time - prev_time\n",
    "            prev_time = curr_time\n",
    "            accum_time = accum_time + exec_time\n",
    "            curr_fps = curr_fps + 1\n",
    "            if accum_time > 1:\n",
    "                accum_time = accum_time - 1\n",
    "                fps = \"FPS: \" + str(curr_fps)\n",
    "                curr_fps = 0\n",
    "\n",
    "            print('Frame Number {}:'.format(cnt - 1))\n",
    "            \n",
    "            cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
    "            cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "            out.write(result)\n",
    "            cv2.imshow(\"result\", result)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print('++++++++ Video End ++++++++')\n",
    "    \n",
    "    vid.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print('\\nTotal elapsed time = ' + str(timer() - start4Total) + ' s\\n')\n",
    "\n",
    "    #yolo.close_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data/yolo.h5 model, anchors, and classes loaded.\n",
      "Video Dim: 1920.0  X  1080.0\n",
      "(416, 416, 3)\n",
      "Found 9 boxes for img\n",
      "8.543250520015135\n",
      "Frame Number 0:\n",
      "(416, 416, 3)\n",
      "Found 9 boxes for img\n",
      "3.6652461371850222\n",
      "Frame Number 1:\n",
      "(416, 416, 3)\n",
      "Found 11 boxes for img\n",
      "3.556310212938115\n",
      "Frame Number 2:\n",
      "(416, 416, 3)\n",
      "Found 12 boxes for img\n",
      "3.799286044901237\n",
      "Frame Number 3:\n",
      "(416, 416, 3)\n",
      "Found 9 boxes for img\n",
      "3.880106419790536\n",
      "Frame Number 4:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.94134767097421\n",
      "Frame Number 5:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.209475582931191\n",
      "Frame Number 6:\n",
      "(416, 416, 3)\n",
      "Found 9 boxes for img\n",
      "3.9627705251332372\n",
      "Frame Number 7:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.128417016007006\n",
      "Frame Number 8:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.8393247870262712\n",
      "Frame Number 9:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.7559478150215\n",
      "Frame Number 10:\n",
      "(416, 416, 3)\n",
      "Found 9 boxes for img\n",
      "3.779005693970248\n",
      "Frame Number 11:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.261963570956141\n",
      "Frame Number 12:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "4.419813103042543\n",
      "Frame Number 13:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "4.087962610879913\n",
      "Frame Number 14:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.963765097083524\n",
      "Frame Number 15:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.843820811016485\n",
      "Frame Number 16:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.806613288121298\n",
      "Frame Number 17:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "3.8397232920397073\n",
      "Frame Number 18:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.8283150559291244\n",
      "Frame Number 19:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "3.793796628015116\n",
      "Frame Number 20:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "3.9592382879927754\n",
      "Frame Number 21:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "4.071080230176449\n",
      "Frame Number 22:\n",
      "(416, 416, 3)\n",
      "Found 7 boxes for img\n",
      "4.30482893390581\n",
      "Frame Number 23:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.92995626013726\n",
      "Frame Number 24:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.127122168196365\n",
      "Frame Number 25:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.173231933033094\n",
      "Frame Number 26:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.325788608053699\n",
      "Frame Number 27:\n",
      "(416, 416, 3)\n",
      "Found 8 boxes for img\n",
      "4.360091264126822\n",
      "Frame Number 28:\n",
      "++++++++ Video End ++++++++\n",
      "\n",
      "Total elapsed time = 132.38992851809599 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from yolo import YOLO\n",
    "#from yolo import detect_video\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_path='/Users/chung/hpbint/VideosHPB/IMAG0011.mp4'\n",
    "    detect_video(YOLO(), video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
