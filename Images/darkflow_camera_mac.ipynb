{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 29896\r\n",
      "-rw-r--r--@  1 chung  staff     23224 Mar  9 18:09 DarkFlow_Mac.ipynb\r\n",
      "-rw-r--r--   1 chung  staff     35141 Feb 26 23:07 LICENSE\r\n",
      "-rw-r--r--   1 chung  staff     11539 Feb 26 23:07 README.md\r\n",
      "drwxr-xr-x   5 chung  staff       170 Mar  8 14:51 \u001b[34mbin\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   5 chung  staff       170 Mar 15 19:08 \u001b[34mbuild\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  14 chung  staff       476 Mar  8 16:43 \u001b[34mcfg\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   8 chung  staff       272 Mar  9 18:07 \u001b[34mckpt\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  12 chung  staff       408 Mar  8 17:36 \u001b[34mdarkflow\u001b[m\u001b[m/\r\n",
      "-rwxr-xr-x@  1 chung  staff      9107 Mar 16 11:24 \u001b[31mdarkflow_camera_mac.ipynb\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@  1 chung  staff      8989 Mar 15 19:09 \u001b[31mdarkflow_camera_win10.ipynb\u001b[m\u001b[m*\r\n",
      "-rw-r--r--   1 chung  staff  14900940 Feb 26 23:07 demo.gif\r\n",
      "-rwxr-xr-x   1 chung  staff        94 Feb 26 23:07 \u001b[31mflow\u001b[m\u001b[m*\r\n",
      "-rw-r--r--@  1 chung  staff        21 Mar  8 16:43 labels.txt\r\n",
      "-rw-r--r--@  1 chung  staff        21 Mar  8 16:43 labels3c.txt\r\n",
      "-rw-r--r--@  1 chung  staff        27 Mar  8 16:43 labels_o.txt\r\n",
      "-rw-r--r--   1 chung  staff    283380 Feb 26 23:07 preview.png\r\n",
      "drwxr-xr-x  12 chung  staff       408 Mar  8 15:15 \u001b[34msample_img\u001b[m\u001b[m/\r\n",
      "-rw-r--r--   1 chung  staff      2575 Feb 26 23:07 setup.py\r\n",
      "drwxr-xr-x   6 chung  staff       204 Mar 15 19:08 \u001b[34mtest\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Example usage: flow --imgdir sample_img/ --model cfg/yolo.cfg --load bin/yolo.weights\r\n",
      "\r\n",
      "Arguments:\r\n",
      "  --gpu            how much gpu (from 0.0 to 1.0)\r\n",
      "  --json           Outputs bounding box information in json format.\r\n",
      "  --threshold      detection threshold\r\n",
      "  --summary        path to TensorBoard summaries directory\r\n",
      "  --binary         path to .weights directory\r\n",
      "  --momentum       applicable for rmsprop and momentum optimizers\r\n",
      "  --pbLoad         path to .pb protobuf file (metaLoad must also be specified)\r\n",
      "  --keep           Number of most recent training results to save\r\n",
      "  --annotation     path to annotation directory\r\n",
      "  --train          train the whole net\r\n",
      "  --config         path to .cfg directory\r\n",
      "  --lr             learning rate\r\n",
      "  --metaLoad       path to .meta file generated during --savepb that corresponds to .pb file\r\n",
      "  --save           save checkpoint every ? training examples\r\n",
      "  --savepb         save net and weight to a .pb file\r\n",
      "  --batch          batch size\r\n",
      "  --help, --h, -h  show this super helpful message and exit\r\n",
      "  --queue          process demo in batch\r\n",
      "  --verbalise      say out loud while building graph\r\n",
      "  --saveVideo      Records video from input video or camera\r\n",
      "  --model          configuration of choice\r\n",
      "  --epoch          number of epoch\r\n",
      "  --labels         path to labels file\r\n",
      "  --imgdir         path to testing directory with images\r\n",
      "  --demo           demo on webcam\r\n",
      "  --load           how to initialize the net? Either from .weights or a checkpoint, or even from scratch\r\n",
      "  --gpuName        GPU device name\r\n",
      "  --dataset        path to dataset directory\r\n",
      "  --trainer        training algorithm\r\n",
      "  --backup         path to backup folder\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./flow --h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera & Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing ./cfg/tiny-yolo-voc.cfg\n",
      "Parsing cfg/tiny-yolo-voc-3c.cfg\n",
      "Loading bin/tiny-yolo-voc.weights ...\n",
      "Successfully identified 63471556 bytes\n",
      "Finished in 0.23761701583862305s\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 16)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 16)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_1                     | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 40)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "2018-03-16 11:26:37.848134: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-03-16 11:26:37.848168: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "Finished in 2.7749319076538086s\n",
      "\n",
      "Press [ESC] to quit demo\n",
      "1.593 FPS^C\n"
     ]
    }
   ],
   "source": [
    "!./flow --model cfg/tiny-yolo-voc-3c.cfg --load bin/tiny-yolo-voc.weights --demo \"../VideosHPB/IMAG0003.mp4\" --saveVideo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
